{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd(\"C:\\\\git\\\\lets_learn\\\\infclean\\\\src\\\\\")\n",
    "include(\"modeling\\\\correlation_lib.jl\")\n",
    "include(\"modeling\\\\util.jl\")\n",
    "using SQLite\n",
    "using CSV\n",
    "using DataFrames: DataFrame, Missing, showall\n",
    "using Statistics, LinearAlgebra, Logging, Random\n",
    "using Gen\n",
    "\n",
    "cd(\"C:\\\\git\\\\lets_learn\\\\infclean\\\\data\\\\mercateo\\\\\")\n",
    "\n",
    "ATTRIBUTES = [:catalog_id,\n",
    "            :article_id,\n",
    "            :destination,\n",
    "            :lower_bound,\n",
    "            :ek_amount,\n",
    "            :vk_amount,\n",
    "            :currency,\n",
    "            :unit,\n",
    "            :tax,\n",
    "            :set_id]\n",
    "\n",
    "db = SQLite.DB()\n",
    "patched_table = CSV.File(\"patched.csv\") |> SQLite.load!(db, \"patched_table\")\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patched_df = parse_ek_data(db, :patched_table)\n",
    "patched_df[1:20, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The EK Model\n",
    "The idea is similar to the rent model: to build a top-down sampler that incorporates correlation knowledge.\n",
    "\n",
    "__However, the occurrence statistics do not give much information on correctness, i.e. a catalog_id isn't necessarily incorrect just because it appears sparsely in the observation dataset.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function ek_model(realization_df)\n",
    "    @info \"-----------------ADV\"\n",
    "    # 1. Pick catalog_id\n",
    "    catalog_id = @trace(uniformly_categorical(realization_df, :catalog_id), :catalog_id)\n",
    "    @info \"CID: $catalog_id\"\n",
    "    \n",
    "    # 2. Pick article_id corresponding to observed co_occurrence with catalog_id\n",
    "    article_id = @trace(co_occurrence(realization_df,\n",
    "                                            [:catalog_id,],\n",
    "                                            :article_id,\n",
    "                                            [String(catalog_id),],\n",
    "                                            false), :article_id)\n",
    "    @info \"AID: $article_id\"\n",
    "\n",
    "    # 3. Pick destination: We assume that the same product from the same supplier\n",
    "    # comes from the same country.\n",
    "    destination = @trace(co_occurrence(realization_df,\n",
    "                                            [:catalog_id, :article_id],\n",
    "                                            :destination,\n",
    "                                            [String(catalog_id), String(article_id)],\n",
    "                                            false), :destination)\n",
    "    @info \"Destination: $destination\"\n",
    "\n",
    "    # 4. Pick lower bound\n",
    "    # Chance to pick a lower bound that has been observed together with aid is high.\n",
    "    # For the same article from the same supplier, higher lower bound should imply\n",
    "    # lower ek. => Vertical learning\n",
    "    lower_bound = @trace(co_occurrence(realization_df,\n",
    "                                            [:catalog_id, :article_id],\n",
    "                                            :lower_bound,\n",
    "                                            [String(catalog_id), String(article_id)],\n",
    "                                            false), :lower_bound)\n",
    "    @info \"LB: $lower_bound\"\n",
    "\n",
    "    # 5. Pick currency\n",
    "    currency = @trace(co_occurrence(realization_df,\n",
    "                                            [:destination],\n",
    "                                            :currency,\n",
    "                                            [String(destination)],\n",
    "                                            false), :currency)\n",
    "    @info \"Currency: $currency\"\n",
    "\n",
    "    # 6. Pick unit\n",
    "    unit = @trace(co_occurrence(realization_df,\n",
    "                                        [:article_id],\n",
    "                                        :unit,\n",
    "                                        [String(article_id)],\n",
    "                                        false), :unit)\n",
    "    @info \"Unit: $unit\"\n",
    "\n",
    "    # 7. Pick tax\n",
    "    tax = @trace(co_occurrence(realization_df,\n",
    "                                    [:article_id, :destination],\n",
    "                                    :tax,\n",
    "                                    [String(article_id), String(destination)],\n",
    "                                    false), :tax)\n",
    "    @info \"Tax: $tax\"\n",
    "\n",
    "    # Pick set_id\n",
    "    set_id = @trace(co_occurrence(realization_df,\n",
    "                                        [:catalog_id, :article_id],\n",
    "                                        :set_id,\n",
    "                                        [String(catalog_id), String(article_id)],\n",
    "                                        false), :set_id)\n",
    "    @info \"SID: $set_id\"\n",
    "\n",
    "    # 9. Pick ek\n",
    "    # ek is heavily correlated with other attributes. Here we use multiple FDs\n",
    "    # to make ek suggestions and sample final ek, using mean and std of the\n",
    "    # suggestions\n",
    "    # TODO replace these FDs with embeddings\n",
    "    # From article_id\n",
    "    aid_unit_ek = numerical_functional_dependency(realization_df,\n",
    "                                            [:article_id, :unit],\n",
    "                                            :ek_amount,\n",
    "                                            [String(article_id), String(unit)],\n",
    "                                            true,\n",
    "                                            false)\n",
    "\n",
    "    aid_cid_unit_ek = numerical_functional_dependency(realization_df,\n",
    "                                            [:article_id, :catalog_id, :unit],\n",
    "                                            :ek_amount,\n",
    "                                            [String(article_id), String(catalog_id), String(unit)],\n",
    "                                            true,\n",
    "                                            false)\n",
    "    set_id_unit_ek = numerical_functional_dependency(realization_df,\n",
    "                                                    [:set_id, :unit],\n",
    "                                                    :ek_amount,\n",
    "                                                    [String(set_id), String(unit)],\n",
    "                                                    true,\n",
    "                                                    false)\n",
    "    mean_ek = mean([aid_unit_ek, aid_cid_unit_ek, set_id_unit_ek])\n",
    "    std_ek = max(std([aid_cid_unit_ek, aid_unit_ek, set_id_unit_ek]), 0.01)\n",
    "    ek_amount = @trace(half_normal(mean_ek, std_ek), :ek_amount => :realization)\n",
    "    @info \"EK: $ek_amount\"\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating log-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disable_logging(LogLevel(-1))\n",
    "\n",
    "for i = 1:5\n",
    "    constraints = make_constraints(patched_df[i, :])\n",
    "    (trace, weight) = Gen.generate(ek_model, (patched_df,), constraints)\n",
    "    println(\"Loglikelihood: $weight\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General problems\n",
    "- Now the dataset is unsorted; Comparing log-likelihoods between e.g. different product categories might be not meaningful, because e.g. the price of smartphones could have a higher variance than printing paper.\n",
    "\n",
    "    $\\to$ Pre-processing the dataset would be meaningful (e.g. partitioning)\n",
    "    \n",
    "    \n",
    "- As occurrence statistics have no real meaning, we may need more information from other places. For e.g. \n",
    "\n",
    "    $\\to$ Use more columns (keyword, ean, manufacturer etc.)\n",
    "    \n",
    "    $\\to$ Capture correlation between categorical columns by learning vector representations\n",
    "    \n",
    "    \n",
    "- Set_id is currently giving too much information. The model is relying on it completely.\n",
    "\n",
    "    $\\to$ Replace it with data columns from which set_id is derived."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
