{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20190923 - Rent Model\n",
    "Implements a generative model that incorporates 4 random variables:\n",
    "- __State__: Drawn from categorical distribution; weight of each state is proportional to population and edit score given observation\n",
    "- __City__: Drawn from categorical distribution; weight of each city is based on previously chosen state, proportional to population and edit distance from given observation\n",
    "- __Zip__: Paired with city, conditioned on edit score\n",
    "- __Rent__: Drawn from normal distribution, with mean equals mean rent and sigma set fix \n",
    "\n",
    "Idea: For any observed tuple (does not matter if dirty or not), the rent model takes it as input and samples a new tuple The attribute values of it are drawn from corresponding distributions, with parameters calculated based on prior knowledge (we give it a list of states, cities, population and mean rent) and observation (i.e. compare edit distance). If no observation is given, the model samples only based on external knowledge.\n",
    "\n",
    "With this model, 3 things can be done:\n",
    "- Sample fake data with ```Gen.simulate(model, args)```\n",
    "- Sample tuples for given constraints, e.g. ```rent!=7 and state != \"Bayern\"```, and evaluate the log probability of that tuple\n",
    "- Do importance resampling/MCMC and other inference algorithms to find the most probable tuple given observation and constraints iteratively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preparations\n",
    "Import packages, implement some helper functions for reading external data etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "using StringDistances\n",
    "using Gen\n",
    "using DataFrames\n",
    "\n",
    "function read_csv(file_path::String)\n",
    "    return CSV.File(file_path) |> DataFrame!\n",
    "end\n",
    "\n",
    "function word_to_distance_dict(word, word_list)\n",
    "    return [w => StringDistances.evaluate(Levenshtein(), word, w) for w in word_list]\n",
    "end\n",
    "\n",
    "function get_word_with_typo(word::String, action, pos, chr)\n",
    "    # Action: 1 for insertion, 2 for removal, 3 for replacement\n",
    "    if action==1\n",
    "        converted_chr = convert(Char, chr+96)\n",
    "        return word[1:pos-1]*converted_chr*word[pos:end]\n",
    "    elseif action==2\n",
    "        return word[1:pos-1]*word[pos+1:end]\n",
    "    else\n",
    "        converted_chr = convert(Char, chr+96)\n",
    "        return replace(word, word[pos]=>converted_chr)\n",
    "    end\n",
    "end\n",
    "\n",
    "struct ExtData\n",
    "    state_population_df::DataFrames.DataFrame\n",
    "    state_city_population_mean_rent_df::DataFrames.DataFrame\n",
    "end\n",
    "\n",
    "function init_ext_data(state_population_df, state_city_population_mean_rent_df)\n",
    "    global ext_data\n",
    "    ext_data = ExtData(state_population_df, state_city_population_mean_rent_df)\n",
    "end\n",
    "\n",
    "@gen function add_typo(intention, prob)\n",
    "    if @trace(Gen.bernoulli(prob), :add_more_typo)\n",
    "        # Which action\n",
    "        action = @trace(Gen.uniform_discrete(1, 3), :action)\n",
    "        chr = @trace(Gen.uniform_discrete(1, 26), :chr)\n",
    "        if action == 1\n",
    "            # insertion\n",
    "            pos = @trace(Gen.uniform_discrete(1, length(intention) + 1), :pos)\n",
    "        else\n",
    "            # deletion or replacement\n",
    "            pos = @trace(Gen.uniform_discrete(1, length(intention)), :pos)\n",
    "        end\n",
    "        dirty_intention = get_word_with_typo(intention, action, pos, chr)\n",
    "        return @trace(add_typo(dirty_intention, prob / 2.), :next_typo)\n",
    "    else\n",
    "        return intention\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_edit_score(string1::String, string2::String)\n",
    "    return compare(string1, string2, TokenMax(Levenshtein()))\n",
    "end\n",
    "\n",
    "function get_edit_score(string_list::Array{String}, string::String)\n",
    "    return [compare(i, string, TokenMax(Levenshtein()))  for i in string_list]\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the categorical distribution of state/city, we multiply population with edit score (1 is total match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_weighted_prob_bef_norm(states_or_cities::Array{String}, populations, realization; mask=nothing)\n",
    "    edit_dist_score = [1. for _=1:length(states_or_cities)]\n",
    "    if realization != nothing\n",
    "        edit_dist_score = get_edit_score(states_or_cities, realization)\n",
    "    end\n",
    "    # 5 times gain\n",
    "    # edit_dist_score = [if i > 0.5 i * 5 else i end for i in edit_dist_score]\n",
    "    edit_dist_score = [exp(i*5.) for i in edit_dist_score]\n",
    "    #weighted_pop = populations .* edit_dist_score\n",
    "    weighted_pop = edit_dist_score\n",
    "    if mask != nothing\n",
    "        weighted_pop[mask] .= 0.\n",
    "    end\n",
    "    #println(weighted_pop)\n",
    "    return weighted_pop\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. The model itself\n",
    "- Input: Observed data tuple (could contain missing value), constraints (optional)\n",
    "- Output: A suggestive clean tuple sampled from probabilistic intention model\n",
    "- Procedure:\n",
    "    1. Fetch external data (list of states and cities)\n",
    "    2. Choose state proportionally to population and edit score\n",
    "    3. For chosen state, choose city accordingly\n",
    "        - The current model doesn't allow choosing cities outside the state, as its output should be free of constraint violation.\n",
    "    4. Sample rent\n",
    "\n",
    "- The only prior considered now is the state population, i.e. once a state is chosen, city, zip and rent are conditioned on it. Maybe we should\n",
    "    1. Incorporate the prior of city $P(city)$, zip and rent, and use e.g. $P(city|state=\"Bayern\")P(city)$\n",
    "    2. For real data sets, find reasonable prior knowledge, as e.g. population alone isn't sufficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@gen function rent_model(realized_state, realized_city, realized_zip)\n",
    "    # fetch external data\n",
    "    global ext_data\n",
    "    states_df = ext_data.state_population_df\n",
    "    cities_df = ext_data.state_city_population_mean_rent_df\n",
    "\n",
    "    # CHOOSE STATE PROPORTIONALLY TO POPULATION AND NUMBER OF TYPOS\n",
    "    states_weights = get_weighted_prob_bef_norm(convert(Array{String}, states_df[:, :state]), states_df[:, :population], realized_state)\n",
    "    states_prob = states_weights ./ sum(states_weights)\n",
    "    intended_state_ind = @trace(Gen.categorical(states_prob), :intended_state_ind)\n",
    "    intended_state = states_df[intended_state_ind, :state]\n",
    "\n",
    "    # CHOOSE CITY AND ZIP PROPORTIONALLY TO POPULATION AND NUMBER OF TYPOS\n",
    "    mask = cities_df[:state] .!= states_df[intended_state_ind, :state]\n",
    "    cities_weights = get_weighted_prob_bef_norm(convert(Array{String}, cities_df[:, :city]), cities_df[:, :population], realized_city, mask=mask)\n",
    "    if realized_zip != nothing\n",
    "        zip_edit_score = get_edit_score([string(z) for z in cities_df[:, :zip]], string(realized_zip))\n",
    "        zip_edit_score = [exp(i*5.) for i in zip_edit_score]\n",
    "        cities_weights .*= zip_edit_score\n",
    "    end\n",
    "    cities_prob = cities_weights ./ sum(cities_weights)\n",
    "    intended_city_ind = @trace(Gen.categorical(cities_prob), :intended_city_ind)\n",
    "    intended_city = cities_df[intended_city_ind, :city]\n",
    "    intended_zip = cities_df[intended_city_ind, :zip]\n",
    "\n",
    "    # SAMPLE RENT\n",
    "    rent = @trace(Gen.normal(cities_df[intended_city_ind, :mean_rent], 2.), :rent)\n",
    "\n",
    "    # ADD TYPOS\n",
    "    if realized_city == nothing\n",
    "        realized_city = @trace(add_typo(cities_df[intended_city_ind, :city], 0.2), :realized_city)\n",
    "    end\n",
    "    if realized_state == nothing\n",
    "        realized_state = @trace(add_typo(cities_df[intended_city_ind, :state], 0.2), :realized_state)\n",
    "    end\n",
    "    # println(\"$intended_state; $intended_city; $intended_zip; $rent\")\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_ext_data(read_csv(joinpath(@__DIR__, \"../data/states.csv\")), read_csv(joinpath(@__DIR__, \"../data/cities.csv\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Simulation - Sample ```ys = intended_tuple``` for ```xs = observed_tuple```\n",
    "- Note that we have no constraints here, i.e. for every single attribute value, we don't know if it's clean or not.\n",
    "- Results are quite bad. Reasons:\n",
    "    - We have no constraints, too much freedom for the model\n",
    "    - Parameters of the distributions don't fit. Population should not have such an impact over edit score.\n",
    "    - Measure for edit score is too weak (```TokenMax(Levenshtein())```), need new measure\n",
    "    - Need new strategies, e.g. if ```edit_score(realization, city_a) > threshold```, we eliminate other cities' weights. __This would bring us back to heuristical decision rules!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 10 traces\n",
    "traces = [Gen.simulate(rent_model, (\"Hessen\", \"Frankfurt am Main\", \"60596\")) for _=1:10];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Simulation with constraints - Sample ```ys = intended_tuple``` for ```xs = dirty_or_NA_attr``` and ```constraints = clean_attr```\n",
    "- For each sample that comes out here, we also get a weight\n",
    "\n",
    "$w = log\\frac{p(t,r;x)}{q(t;u,x)q(r;x,t)}$,\n",
    "\n",
    "with $u$ (constraints), $x$ (dirty attr. values), $t, r$ (sample). \n",
    "\n",
    "- If constraints conflict with each other, ```weight = -Inf```\n",
    "\n",
    "Here we test ```[\"Hesssen\", NaN, \"60596\", \"4.\"]``` as an observation. We think the rent is trustworthy and set it as constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = Gen.choicemap()\n",
    "\n",
    "# conflicting constraints will result in -inf weight\n",
    "# constraints[:intended_state_ind] = 5 # Hessen\n",
    "constraints[:rent] = 15.0    # rent = 4EUR/m2\n",
    "#constraints[:intended_city_ind] = 56 # FaM\n",
    "\n",
    "for _=1:10\n",
    "    (trace, weight) = Gen.generate(rent_model, (\"Bayern\", \"Frankfurt am Main\", \"60306\"), constraints)\n",
    "    println(weight)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model thinks that the rent is too low for Hessen, thus gives samples with ```\"Niedersachsen\"``` greater weights.\n",
    "\n",
    "A noticable task is to implement __outlier detection__ or use training data to tune the parameters of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Inference\n",
    "- We setup constraints and number of iterations, and use importance resampling to infer the most probable tuple for given observation.\n",
    "- __Problem__: If the model is large and/or its attributes have large admissible value set, the inference program may fail to traverse through all possible value combinations and stuck at local maxima.\n",
    "- Inference problems of such models are in general non-convex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function do_inference(model, args, constraints, num_iter)\n",
    "    (trace, lml_est) = Gen.importance_resampling(rent_model, args, constraints, num_iter)\n",
    "    return (trace, lml_est)\n",
    "end\n",
    "\n",
    "constraints = Gen.choicemap()\n",
    "constraints[:rent] = 12.25\n",
    "#constraints[:intended_state_ind] = 5\n",
    "\n",
    "trace, lml_est = do_inference(rent_model, (nothing, \"munich\", \"80331\"), constraints, 100000)\n",
    "println([ext_data.state_city_population_mean_rent_df[trace[:intended_city_ind], :state], ext_data.state_city_population_mean_rent_df[trace[:intended_city_ind], :city],\n",
    "ext_data.state_city_population_mean_rent_df[trace[:intended_city_ind], :zip], trace[:rent]])\n",
    "println(lml_est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Immediate tasks\n",
    "- Incorporate different types of integrity constraint (quantitative statistics, denial rules etc.)\n",
    "- Try out parameter learning using training data\n",
    "- Try out realistic data sets!\n",
    "- Test out inference performance and scalability by enlarging the model (incorporate more attributes)\n",
    "- Find other packages/libraries that are useful for this project\n",
    "- Think about whether stay with Julia or switch to Python for flexibility and extendability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Future directions\n",
    "- How to generalize the process of model building? How to allow user to specify a model without hard coding? --> Constraint definition by using specific expressions\n",
    "- How to combine mixed types of integrity constraints? How to specify them?\n",
    "- Improve inference program:\n",
    "    - Pruning sample space\n",
    "    - Performance comparison between algorithms (MCMC, SVI, MH)\n",
    "    - Neural network?\n",
    "- Supervised, weakly-supervised and unsupervised learning --> How? Possible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__More buzzwords__: Featurization, error detection, outlier detection, grouding, graphical models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
